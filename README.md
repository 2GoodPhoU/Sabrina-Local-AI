# TODO
- integration
   - add LLM 
   - add standardized formats and framework for LLM input/output to communicate to core.py
   - LLM short term memory storage
   - training feedback loop
   - presence+task integration
- vision
   - implement yolov8 again
- presence
   - fix clickthrough, implement position saving
   - implement acutal animations
- improve automation
   - add click and drag fuctionality
   - add scroll functionality
   - add shortcuts for common PC actions
- general
   - auto download requirements
   - startup via .exe

# Sabrina AI - Enhanced Local AI Assistant

## ğŸš€ Project Overview

Sabrina AI is a privacy-focused, locally-running AI assistant that combines advanced voice interaction, screen awareness, automation, and smart home control into a comprehensive, intelligent system.

## ğŸ“‚ Project Structure

```
/SABRINA-LOCAL-AI
â”‚-- /core
â”‚   â”‚-- core.py  # Main AI Orchestration Engine
â”‚   â”‚-- memory.py  # Memory & recall system
â”‚   â”‚-- config.py  # Configuration settings
â”‚-- /services  # AI Services & Modules
â”‚   â”‚-- /hearing  # Voice recognition
â”‚   â”‚   â”‚-- hearing.py  # Whisper ASR-based recognition
â”‚   â”‚-- /vision  # AI-powered screen analysis
â”‚   â”‚   â”‚-- constants.py
â”‚   â”‚   â”‚-- vision_core.py  # Screen capture & tracking
â”‚   â”‚   â”‚-- vision_ocr.py  # Text extraction
â”‚   â”‚   â”‚-- vision_detection.py  # UI element detection
â”‚   â”‚-- /automation  # PC automation
â”‚   â”‚   â”‚-- automation.py  # Keyboard & mouse control
â”‚   â”‚-- /smart_home  # Home automation
â”‚   â”‚   â”‚-- smart_home.py  # Google Home & Home Assistant control
â”‚   â”‚-- /voice  # Voice synthesis
â”‚   â”‚   â”‚-- voice.py  # TTS-based voice output
â”‚-- /models  # AI models & training data
â”‚   â”‚-- /vosk-model  # Voice recognition models
â”‚   â”‚-- /yolov8  # Object detection models
â”‚-- /scripts  # Utility scripts
â”‚   â”‚-- start_services.py  # Starts AI services
â”‚   â”‚-- setup_env.py  # Environment setup
â”‚-- /config  # Configuration files
â”‚   â”‚-- settings.yaml  # System configuration
â”‚   â”‚-- api_keys.env  # External API credentials
â”‚-- /data  # Storage for logs, databases
â”‚   â”‚-- logs/  # System logs
â”‚   â”‚-- db/  # Database files
â”‚-- /tests  # Unit and integration tests
â”‚-- README.md  # Project documentation
â”‚-- requirements.txt  # Project dependencies
```

## âœ¨ Key Features

### ğŸ—£ï¸ Voice Interaction
- Wake word detection with Vosk
- Speech recognition using Whisper ASR
- Text-to-speech with Jenny TTS
- Configurable voice settings

### ğŸ‘€ Vision & Screen Awareness
- Advanced screen capture
- Optical Character Recognition (OCR)
- UI element detection with YOLOv8
- Active window tracking and analysis

### ğŸ’» PC Automation
- Cross-application keyboard/mouse control
- Task automation
- Workflow recording and playback
- Context-aware UI interaction

### ğŸ¡ Smart Home Integration
- Google Home API integration
- Home Assistant support
- Device control and routine management
- Cross-platform smart home automation

### ğŸ¤– AI Presence
- Animated avatar with dynamic expressions
- Context-aware interactions
- Mood-based visual feedback

## ğŸ› ï¸ Technology Stack

### Core Technologies
- **Language**: Python 3.10+
- **Frameworks**: 
  - FastAPI
  - PyTorch
  - PyQt5
- **Machine Learning**:
  - Whisper
  - YOLOv8
  - Vosk

### Speech Processing
- **ASR**: Whisper
- **TTS**: Jenny TTS
- **Wake Word**: Vosk

### Computer Vision
- **Image Processing**: OpenCV
- **Object Detection**: YOLOv8
- **OCR**: Tesseract, PaddleOCR

### Automation
- **Input Control**: PyAutoGUI
- **Window Management**: PyGetWindow

## ğŸ”§ Installation & Setup

### Prerequisites
- Python 3.10+
- Docker (recommended)
- CUDA-capable GPU (optional, for accelerated processing)

### Quick Setup
```bash
# Clone the repository
git clone https://github.com/yourusername/sabrina-ai.git
cd sabrina-ai

# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Run setup script
python scripts/setup_env.py
```

### Running Sabrina AI
```bash
# Start voice service
python services/voice/voice_api.py

# Run main system
python scripts/start_sabrina.py
```

## ğŸ“‹ Command Line Options
- `--config`: Specify configuration file
- `--debug`: Enable debug mode
- `--no-voice`: Disable voice output
- `--no-vision`: Disable vision processing

## ğŸ¤ Contributing
1. Fork the repository
2. Create a feature branch: `git checkout -b feature/your-feature`
3. Commit changes: `git commit -m 'Add your feature'`
4. Push branch: `git push origin feature/your-feature`
5. Submit a pull request

## ğŸ”¬ Current Development Focus
- Improved conversational memory
- Enhanced AI reasoning
- VR/AR integration
- Continuous learning mechanisms

## ğŸ“„ License
MIT License

## ğŸŒŸ Project Vision
Sabrina AI aims to create a fully embodied, privacy-first AI assistant that seamlessly integrates with your digital and physical environment.