# Sabrina-Local-AI

AI Assistant

install:
https://www.freedesktop.org/wiki/Software/PulseAudio/Ports/Windows/Support/

How to use:

python -m venv .venv
.venv\Scripts\Activate
pip install -r requirements.txt
cd into scripts
python sabrina_local_ai.py



install Python 3.10
1ï¸âƒ£ Set Up a Python Virtual Environment
Before working on the repo, letâ€™s set up a clean Python environment to avoid dependency conflicts.

Commands to Set Up a Virtual Environment

# Create virtual environment
python -m venv sabrina_env

# Activate the environment
# Windows:
sabrina_env\Scripts\activate

# Linux/macOS:
source sabrina_env/bin/activate

# Install dependencies
pip install -r requirements.txt

This ensures your Python scripts run in an isolated environment.


2ï¸âƒ£ Review & Refactor Existing Code
Weâ€™ll go through each script and reorganize them into a structured package.

New Project Structure (Planned)

Sabrina AI
â”‚â”€â”€ configs/                 # ğŸ› ï¸ Configuration files
â”‚   â”œâ”€â”€ system.yaml          # Global system settings
â”‚   â”œâ”€â”€ docker-compose.yml   # Docker container definitions
â”‚   â”œâ”€â”€ api_endpoints.json   # API route definitions
â”‚   â”œâ”€â”€ dependencies.txt     # Package dependencies (pip, apt, etc.)
â”‚
â”‚â”€â”€ scripts/                 # ğŸ­ Core scripts (high-speed execution)
â”‚   â”œâ”€â”€ pc_automation.py     # Controls keyboard/mouse inputs
â”‚   â”œâ”€â”€ shared_memory.py     # Manages ZeroMQ/Redis shared memory
â”‚   â”œâ”€â”€ vision_processing.py # OCR & object recognition (PaddleOCR/OpenCV)
â”‚   â”œâ”€â”€ hearing.py       # Whisper ASR for speech-to-text
â”‚   â”œâ”€â”€ voice.py      # Jenny TTS for speech synthesis
â”‚
â”‚â”€â”€ api/                     # ğŸŒ API services (FastAPI/Flask)
â”‚   â”œâ”€â”€ main.py              # API gateway (manages interactions)
â”‚   â”œâ”€â”€ vision_api.py        # Handles vision requests
â”‚   â”œâ”€â”€ voice_api.py         # Handles voice requests
â”‚   â”œâ”€â”€ automation_api.py    # Handles PC control & automation
â”‚
â”‚â”€â”€ docker/                  # ğŸ³ Docker files for modular services
â”‚   â”œâ”€â”€ vision.Dockerfile    # OCR & Object Detection (PaddleOCR)
â”‚   â”œâ”€â”€ voice.Dockerfile     # Jenny TTS
â”‚   â”œâ”€â”€ hearing.Dockerfile   # Whisper ASR
â”‚   â”œâ”€â”€ home_assistant.Dockerfile # Smart home control
â”‚   â”œâ”€â”€ base.Dockerfile      # Base image (common dependencies)
â”‚
â”‚â”€â”€ containers/              # ğŸ“¦ Containerized runtime storage (volumes, logs)
â”‚   â”œâ”€â”€ vision/              # Vision model output/logs
â”‚   â”œâ”€â”€ voice/               # Voice processing logs
â”‚   â”œâ”€â”€ hearing/             # Hearing processing logs
â”‚   â”œâ”€â”€ automation/          # PC control logs
â”‚
â”‚â”€â”€ startup/                 # ğŸš€ Startup & orchestration
â”‚   â”œâ”€â”€ start.sh             # Main script to spin up everything
â”‚   â”œâ”€â”€ stop.sh              # Clean shutdown script
â”‚
â”‚â”€â”€ tests/                   # ğŸ§ª Unit & integration tests
â”‚   â”œâ”€â”€ test_vision.py       # Tests for vision processing
â”‚   â”œâ”€â”€ test_voice.py        # Tests for AI voice processing
â”‚   â”œâ”€â”€ test_hearing.py      # Tests for user voice processing
â”‚   â”œâ”€â”€ test_automation.py   # Tests for PC automation
â”‚
â”‚â”€â”€ docs/                    # ğŸ“– Documentation & research
â”‚   â”œâ”€â”€ architecture.md      # AI embodiment system architecture
â”‚   â”œâ”€â”€ api_reference.md     # API endpoints & usage
â”‚   â”œâ”€â”€ dependencies.md      # Details of all dependencies
â”‚
â””â”€â”€ README.md                # ğŸ“œ Overview of the project


3ï¸âƒ£ Integrate Screen & Application Awareness
We need real-time screen visibility so Sabrina can recognize objects, text, and applications.
This will be handled via OCR & screen monitoring.

Planned Libraries & Features
Tesseract OCR â†’ Extract on-screen text.
PyGetWindow â†’ Detect currently focused window.
MSS (Screen Capture) â†’ Capture the screen in real time.

4ï¸âƒ£ Enable Seamless Window Switching
Sabrina needs to focus on different applications dynamically.

Solution
PyGetWindow â†’ Get & switch active windows.
PyAutoGUI â†’ Automate window switching.

5ï¸âƒ£ Implement PC Automation & Command Execution
Sabrina should control the PC & execute commands dynamically.

Planned Libraries
PyAutoGUI â†’ Mouse & keyboard automation.
Subprocess â†’ Execute system commands.

6ï¸âƒ£ Voice-Guided Execution
Sabrina should provide real-time verbal feedback.

Planned Features
Jenny TTS â†’ Speak responses.
Whisper ASR â†’ Process voice commands.











Manually Start Node-RED First (Without PM2)

1ï¸âƒ£ Start Node-RED normally:
powershell
"node-red"


2ï¸âƒ£ Try accessing it in your browser:
http://localhost:1880


ğŸ”¥ Proposed Design for AI Vision & Automation
ğŸŸ¢ Core Technologies
Function	Tool/Library
Screen Capture (Full or App-Specific)	mss, pygetwindow, pywinctl
OCR (Text Recognition)	pytesseract
Object Recognition (Non-Text Elements)	YOLOv8, OpenCV
PC Automation (Mouse, Keyboard)	pyautogui, keyboard
Voice Interaction	Jenny TTS, pyttsx3
Voice Commands (Listening to You)	Whisper ASR
âœ… Phase 1: Set Up Full-Screen & App-Specific Vision
We need Sabrina to see both the entire screen and specific applications. Instead of scanning everything, we will:

Detect active applications & windows
Capture only the relevant region

âœ… Phase 2: Object Detection Instead of Just Text
Since you want Sabrina to see objects, weâ€™ll integrate YOLOv8 (for object recognition) to detect UI elements, buttons, and on-screen objects.

âœ… Phase 3: Automating PC Actions
Now that Sabrina can see the screen, letâ€™s allow her to perform actions like: 1ï¸âƒ£ Clicking buttons on screen
2ï¸âƒ£ Pressing keys when events are detected
3ï¸âƒ£ Executing scripts or programs based on vision

âœ… Phase 4: Voice Responses While Acting
Sabrina should talk while performing actions using Jenny TTS.